---
title: "16S rRNA Microbiome Data Analysis Workflow"
author: "Irene Yang"
date: "4/2/2018"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup chunk 0, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load packages

```{r, warning=FALSE,message=FALSE}

library(dada2); packageVersion("dada2")
library(ShortRead); packageVersion("ShortRead")
library(phyloseq); packageVersion("phyloseq")
library(ggplot2); packageVersion("ggplot2")
```

### Change the path to location of files.

```{r}

# Set path to the sequence data files

path <- "~/Desktop/N741/2018Week7/Mom_Fastq"

fileNames <- list.files(path)

list.files(path)
```

### Read in sample names

Using the `dada2` pipeline, first read in the names of the .fastq files. Then manipulate those names as character variables, using regular expressions to create lists of the forward and reverse read .fastq files in *matched* order.

```{r}

# Forward and reverse fastq filenames should have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq

# Start by reading in the names of the .fastq files

fnFs <- sort(list.files(path, pattern="_R1_001.fastq"))
fnRs <- sort(list.files(path, pattern="_R2_001.fastq", full.names = "TRUE"))

# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq

sample.names <- sapply(strsplit(fnFs, "_"), `[`, 1)

# Specify the full path to the fnFs and fnRs
fnFs <- file.path(path, fnFs)
fnRS <- file.path(path, fnRs)
fnFs[1:3]
fnRS[1:3]
```

### Generate quality profiles of the reads

```{r}

# Visualize the quality profile of the first two files containing forward reads

plotQualityProfile(fnFs[1:2])

```

```{r}

# Visualize the quality profile of the first two files containing reverse reads

plotQualityProfile(fnRs[1:2])

```


### Filter and Trim

Typical filtering parameters were used:  
- `maxN = 0` -- `dada2` requires that there be no N's in a sequence
- `truncQ = 2` -- truncate reads at the first instance of a quality less than or equal to \code{truncQ}#.
- `maxEE` = 2 -- sets the maximum number of expected errors allowed in a read, which is a better filter than simply averaging quality scores.

Note: Decision made to trim conservatively given the robustness of dada2 to lower quality sequences. Trimmed at 220 (forward) and 180 (reverse).  Overlap between forward and reverse reads was ensured. 

```{r}

# Make a directory and filenames for the filtered fastqs
 
# Place filtered files in a filtered/ subdirectory

filt.path <- file.path(path, "filtered")
if(!file_test("-d", filt.path)) dir.create(filt.path)
filtFs <- file.path(filt.path, paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(filt.path, paste0(sample.names, "_R_file.fastq.gz"))

# Filter the forward and reverse reads

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(220,180), maxN=0, maxEE=c(2,5), truncQ = 2, multithread=TRUE, compress=FALSE)

list(out)

##lenctruncation 
```

### Learn the Error Rates

```{r, results="hide"}

errF <- learnErrors(filtFs, multithread = TRUE)
errR <- learnErrors(filtRs, multithread = TRUE)

```

```{r}

# Visualize the estimated error rates by plotting the forward and reverse reads

plotErrors(errF, nominalQ=TRUE)

plotErrors(errR, nominalQ = TRUE)

```

### Dereplication

```{r, results="hide"}

# Dereplicate

derepFs <- derepFastq(filtFs, verbose=TRUE)
derepRs <- derepFastq(filtRs, verbose=TRUE)

# Name the derep-class objects by the sample names

names(derepFs) <- sample.names
names(derepRs) <- sample.names

```

### Sample Inference

Infer the sequence variants in each sample (second dada pass)

```{r, results="hide"}

# First with the Forward reads

dadaFs <- dada(derepFs, err = errF, multithread = TRUE)

# Then with the Reverse reads

dadaRs <- dada(derepRs, err = errR, multithread = TRUE)

```

```{r}

# Inspect the dada-class objects returned by the dada function

dadaFs[[1]]
dadaRs[[1]]

```

We can see that the algorithm has inferred 99 unique sequence variants from the forward reads and 87 from the reverse reads.

### Merge Paired Reads

We can eliminate further spurious sequence variants by merging overlapping reads. The core function is `mergePairs` and it depends on the forward and reverse reads being in matching order at the time they were dereplicated.

```{r}

# Merge the denoised forward and reverse reads

mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = TRUE )

```

```{r}

# Inspect the merged data.frame from the first sample

head(mergers[[1]])

```

### Sequence Table Construction

We will now construct the sequence table, this being analogous to the "OTU table" produced by other methods.

```{r}

# Construct sequence table

seqtab <- makeSequenceTable(mergers)

# Consider the table

dim(seqtab)
class(seqtab)

# Inspect the distribution of sequence lengths

table(nchar(getSequences(seqtab)))

```

```{r}

seqtab2 <- seqtab[,nchar(colnames(seqtab)) %in% seq(250, 256)]

dim(seqtab2)
class(seqtab2)
table(nchar(getSequences(seqtab2)))

```

### Remove Chimeras

```{r}

# Remove chimeric sequences

seqtab2.nochim <- removeBimeraDenovo(seqtab2, method = "consensus", multithread = TRUE, verbose=TRUE)

dim(seqtab2.nochim)

sum(seqtab2.nochim)/sum(seqtab2)

```

### Track Reads through the Pipeline

```{r}

getN <- function(x) sum(getUniques(x))
pctSurv <- rowSums(seqtab2.nochim)*100/out[,1]
track <- cbind(out, sapply(dadaFs, getN), sapply(mergers, getN), rowSums(seqtab), rowSums(seqtab2.nochim), pctSurv)
colnames(track) <- c("input", "filtered", "denoised", "merged", "tabled", "nonchimeric", "% passing")
rownames(track) <- sample.names
head(track)

#Calculate average of nonchimeric reads per sample
mean(track[,"nonchimeric"])
```

### Assign Taxonomy

GreenGenes 13_8 reference will be used.

```{r}

# Assign taxonomy

# First initialize random number generator for reproducibility

set.seed(100)
getwd()
path

# list.files omitted to save space on rmarkdown

taxa <- assignTaxonomy(seqtab2.nochim, "~/Desktop/N741/2018Week7/Mom_Fastq/gg_13_8_train_set_97.fa", multithread = TRUE)
unname(head(taxa))

```

Inspect the taxonomic assignments:

```{r}

taxa.print <- taxa #Removing sequence rownames for display only
rownames (taxa.print) <- NULL
head(taxa.print)
```

### Construct a Phylogenetic Tree

```{r, results="hide"}

library(DECIPHER)
seqs <- getSequences(seqtab2.nochim)

# This next command will allow propagation of sequence names to the tip labels of the tree
names(seqs) <- seqs
alignment <- AlignSeqs(DNAStringSet(seqs), anchor=NA)

# Construct tree

library(phangorn)

phang.align <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phang.align)
treeNJ <- NJ(dm) # Tip order will not equal sequence order
fit <- pml(treeNJ, data=phang.align)

## negative edges length changed to 0.

fitGTR <- update(fit, k=4, inv=0.2)
fitGTR <- optim.pml(fitGTR, model="GTR", optInv=TRUE, optGamma=TRUE, 
                    rearrangement = "stochastic", control=pml.control(trace=0))
detach("package:phangorn", unload=TRUE)

```

### Handoff to `phyloseq`

Our next activity will be to hand off the data to the `phyloseq` package for analysis. This package requires three items: the "OTUtable," the taxonomy table, and data about the samples. The first two items are directly available at the end of your `dada2`run, and you can import the latter as a .csv file. 

```{r}

# Import metadata file.

samdf <- read.csv("~/Desktop/N741/2018Week7/Mom_Metadata.csv",header=TRUE)

rownames(samdf) <- samdf$Sample_ID

rownames(samdf)

rownames(seqtab2.nochim)

```

Create the phyloseq object.

```{r}

library(phyloseq)

# Create phyloseq object

ps <- phyloseq(otu_table(seqtab2.nochim, taxa_are_rows=FALSE), 
               sample_data(samdf),
               tax_table(taxa),
               phy_tree(fitGTR$tree))

# Describe it

ps

```

### Diversity in Microbial Ecology

```{r, results="hide"}

# Plot alpha-diversity

plot_richness(ps, x="Groups", measures = c("Shannon"))
        theme_bw()
        
plot_richness(ps, x="Groups", measures = c("Chao1"))
        theme_bw()
        
```

### Ordinate

Using the Bray-Curtis dissimilarity index.

```{r, results="hide"}

# Ordinate with Bray-Curtis

ord.nmds.bray <- ordinate(ps, method="NMDS", distance="bray")

```

```{r}

plot_ordination(ps, ord.nmds.bray, color="Groups", title="Bray NMDS")

```

We see that ordination picks out a separation between maternal and newborn samples.

### Bar Plots   

```{r}

# Create bar plots for top 10 OTUs

top10 <- names(sort(taxa_sums(ps), decreasing = TRUE))[1:10]
ps.top10 <- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))
ps.top10 <- prune_taxa(top10, ps.top10)

plot_bar(ps.top10, fill="Phylum", facet_grid=~Groups)

plot_bar(ps.top10, fill="Class", facet_grid=~Groups)

plot_bar(ps.top10, fill="Order", facet_grid=~Groups)

plot_bar(ps.top10, fill="Family", facet_grid=~Groups)

plot_bar(ps.top10, fill="Genus", facet_grid=~Groups)
```

```{r}
# Plot richness

plot_richness(ps, "Groups", "Sample_Type")

```
```{r}

library(RColorBrewer)
packageVersion("RColorBrewer")

```

```{r}

# Why is filtering not working?

psr <- transform_sample_counts(ps, function(x) x / sum(x))
psfr <- filter_taxa(psr, function(x) mean(x) > 1e-5, TRUE)

ps

psr

psfr
```

```{r}
library(DESeq2)

diagdds = phyloseq_to_deseq2(ps, ~ Groups)
# calculate geometric means prior to estimate size factors
gm_mean = function(x, na.rm=TRUE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}
geoMeans = apply(counts(diagdds), 1, gm_mean)
diagdds = estimateSizeFactors(diagdds, geoMeans = geoMeans)
diagdds = DESeq(diagdds, fitType="local")


res = results(diagdds)
res = res[order(res$padj, na.last=NA), ]
alpha = 0.01
sigtab = res[(res$padj < alpha), ]
sigtab = cbind(as(sigtab, "data.frame"), as(tax_table(ps)[rownames(sigtab), ], "matrix"))
head(sigtab)

posigtab = sigtab[sigtab[, "log2FoldChange"] > 0, ]
posigtab = posigtab[, c("baseMean", "log2FoldChange", "lfcSE", "padj", "Phylum", "Class", "Family", "Genus")]

library("ggplot2")
theme_set(theme_bw())
sigtabgen = subset(sigtab, !is.na(Genus))
# Phylum order
x = tapply(sigtabgen$log2FoldChange, sigtabgen$Phylum, function(x) max(x))
x = sort(x, TRUE)
sigtabgen$Phylum = factor(as.character(sigtabgen$Phylum), levels=names(x))
# Genus order
x = tapply(sigtabgen$log2FoldChange, sigtabgen$Genus, function(x) max(x))
x = sort(x, TRUE)
sigtabgen$Genus = factor(as.character(sigtabgen$Genus), levels=names(x))
ggplot(sigtabgen, aes(y=Genus, x=log2FoldChange, color=Phylum)) + 
  geom_vline(xintercept = 0.0, color = "gray", size = 0.5) +
  geom_point(size=6) + 
  theme(axis.text.x = element_text(angle = -90, hjust = 0, vjust=0.5))

#try box and whiskers plot
ggplot2.boxplot(data=)
```

### References

Callahan, B. J., Sankaran, K., Fukuyama, J. A., McMurdie, P. J., & Holmes, S. P. (2017). Bioconductor workflow for microbiome data analysis: From raw reads to community analyses. Retrieved from: https://bioconductor.org/help/course-materials/2017/BioC2017/Day1/Workshops/Microbiome/MicrobiomeWorkflowII.html#references